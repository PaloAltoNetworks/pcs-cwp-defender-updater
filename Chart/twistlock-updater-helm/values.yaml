compute:
  api_endpoint:                   # *Endpoint of Prisma Cloud Compute Console. Can be found under System > Utilities
  username:                       # Username to be used for Prisma Cloud Compute API calls. For SaaS, it can be the value of Access Key
  password:                       # Password to be used for Prisma Cloud Compute API calls. For SaaS, it can be the value of Secret Key
  secret:  compute-secret         # Name of the Secret to be used
  secret_store:                   # Integrate with External Secrets Operator 
    name:                         # Name of the Secrets Store where the Access to Prisma is located
    kind: ClusterSecretStore      # Secrets Store kind
    refresh_interval: 1h          # Secrets refresh interval
    remote_key:                   # Remote secret name
  skip_verify: false              # Skip TLS verification
 
job:
  cronjob_enabled: true           # Enables CronJob execution. If not enabled, no persistant volume and cronJob will be created
  has_volume: false               # Verifies if job has Persistant Volume. If set to false, then no Persistant Volume will be created.
  schedule: "0 0 * * Sun"         # Time Schedule where the CronJob will be executed. Refer to https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/
  timezone: "Etc/UTC"             # Time zone of current CronJob. if not set the Time will be UTC. Refer to https://en.wikipedia.org/wiki/List_of_tz_database_time_zones to get your current time zone
  image_name:                     # *Name of the image to be used. Must be full path ej REGISTRY_NAME/IMAGE_NAME:IMAGE_TAG
  image_pull_policy: Always       # Pull policy of the CronJob image.
  image_pull_secret: twistlock-updater-pull-secret # Name of the secret needed to pull the CronJob image.
  registry:                       # Variables used to authenticate with external registry to pull the CronJob image. Not needed if the secret has already been created                  
    name:                         # Name of the registry
    username:                     # Username used for authentication.
    password:                     # Password used for authentication.
    dockerconfigjson:             # Credentials for pulling the CronJob image. It is the base 64 encoded of a Docker config file in JSON format. Not needed if the secret has already been created or registry values are set. 
  secret_store:                   # Integrate with External Secrets Operator
    name:                         # Name of the Secrets Store
    kind: ClusterSecretStore      # Secrets Store kind
    refresh_interval: 1h          # Secrets refresh interval
    remote_key:                   # Remote secret name
  role_arn:                       # AWS role ARN for CronJob
  storage:                        # Storage settings for PersistantVolumeClaim. Refer to https://kubernetes.io/docs/concepts/storage/persistent-volumes/
    access_mode: ReadWriteOnce    # Storage access mode for CronJob Persistant Volume
    size: 1Gi                     # Storage size for CronJob Persistant Volume
    class_name:                   # Storage class for CronJob Persistant Volume. If not set, it will use the default Storage Class
    volume_name:                  # Name of the volume used. Used when a needs to reuse a existing PV
  debug: false                    # Print extended output of the CronJob
  init_configmap:                 # Initial DeamonSet config in format of ConfigMap. You can use the following kubectl command: 'kubectl create configmap ${CONFIGMAP_NAME} --from-file=daemonset.yaml'
  annotations:                    # CronJob annontations. Refer to https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  start_now: true                 # Starts a Job to perform the defender installation process
  start_ttl:                      # Seconds that the start Job will be kept. If set to 0 will delete after the Job succeded or failed
  delete_all: true                # Delete all created resources by any the job if 'helm uninstall' command is executed 
  successful_cronjobs: 3          # Amount of successfull CronJobs to be kept. If set to 0, none successfull CronJobs will be kept.
  failed_cronjobs: 1              # Amount of failed CronJobs to be kept. If set to 0, none failed CronJobs will be kept.
  node_selector:                  # Node Selector for executed Jobs
#    key: value

defender:
  console_name: ""                # Name of the console to be connected to. Not needed for SaaS version. For self-hosted, if not set, it will take the first SAN Name that appears under Manage > Defenders > Names
  communication_port: ""          # Overrides the Defender - Console default communication port.
  orchestrator: kubernetes        # Orchestartor to be used. Only tested with kubernetes
  container_runtime: containerd   # Name of container runtime to be used. Can be only the following values: docker, containerd or crio.
  collect_pod_labels: false       # Allow collection of labels on pods
  monitor_service_accounts: false # Allow service account monitoring
  cluster_name_resolving_method: default # Is the method used to resolve the cluster name, could be default, manual or api-server.
  cluster_name: ""                # Overrides the name of the cluster to be used. By default, the defender detects the cluster name. It is required if the cluster_name_resolving_method is set to manual
  runtime_socket_path: ""         # Container runtime socket path
  node_selector: ''               # Specify on which nodes will the deamonset apply to. Format: 'key: "value"'
  role_arn: ""                    # AWS role ARN for DaemonSet defender 
  unique_hostname: false          # Assign unique hostnames to each defended host
  monitor_istio: false            # Allow istio monitoring
  bottlerocket: false             # Deployment made over BottleRocket OS nodes
  gke_autopilot: false            # Deployment made over GKE Autopilot
  talos: false                    # Deployment made over Talos nodes
  image_name: ""                  # Overrides the default defender image to be used
  image_pull_secret: ""           # Secret for pulling the defender image
  selinux: false                  # Deployment made using SELinux Policies
  privileged: false               # Set DaemonSet Pods as Privileged 
  cpu_limit: 0                    # Sets the limit of Defender CPU usage
  memory_limit: 0                 # Sets the limit of Defender Memory usage
  priority_class_name: ""         # Name of the PriorityClass. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/
  project_id: ""                  # Project ID where the Defender is going to point to. Used for self-hosted only.
  region: ""                      # Cloud region where the cluster is localed
  proxy:                          # Proxy settings. Needed if defender requires to connect to a proxy before connecting to the compute console
    ca:                           # CA Bundle for connecting to the proxy
    httpProxy:                    # Proxy URL
    noProxy:                      # Pods that bypass the proxy
    password:                     # Password to be used to connect to the proxy
    user:                         # User to be used to connect to the proxy
  tolerations:                    # Tolerations configuration. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
#  - effect: NoSchedule           # Toleration effect
#    key: key1                    # Toleration key
#    operator: Equels             # Toleration operator
#    toleration_seconds: 0        # Toleration seconds
#    value: value1                # Toleration value
#  - effect: NoExecute 
#    key: key1
#    operator: Exists
#    toleration_seconds: 0
  annotations:                    # Defender DaemonSet annotations
#    annotation1: test

# NOTES 
# - If it has * in it's description, means it is a required value
# - If  the secret compute.secret exists already, there's no need to define the values of compute.username and compute.password
# - If the secret job.image_pull_secret exists already, there's no need to define the value job.pull_secret_dockerconfigjson